{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRADUATE EMPLOYABILITY PREDICTOR - BY: Timur, Anish, Sean, Rahul and David"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "0znB505UCQE7"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "id": "3beef593",
    "outputId": "0289bf0d-d958-43d2-9414-1ec463b78102"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>College_ID</th>\n",
       "      <th>IQ</th>\n",
       "      <th>Prev_Sem_Result</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Academic_Performance</th>\n",
       "      <th>Internship_Experience</th>\n",
       "      <th>Extra_Curricular_Score</th>\n",
       "      <th>Communication_Skills</th>\n",
       "      <th>Projects_Completed</th>\n",
       "      <th>Placement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CLG0030</td>\n",
       "      <td>107</td>\n",
       "      <td>6.61</td>\n",
       "      <td>6.28</td>\n",
       "      <td>8</td>\n",
       "      <td>No</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CLG0061</td>\n",
       "      <td>97</td>\n",
       "      <td>5.52</td>\n",
       "      <td>5.37</td>\n",
       "      <td>8</td>\n",
       "      <td>No</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CLG0036</td>\n",
       "      <td>109</td>\n",
       "      <td>5.36</td>\n",
       "      <td>5.83</td>\n",
       "      <td>9</td>\n",
       "      <td>No</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CLG0055</td>\n",
       "      <td>122</td>\n",
       "      <td>5.47</td>\n",
       "      <td>5.75</td>\n",
       "      <td>6</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CLG0004</td>\n",
       "      <td>96</td>\n",
       "      <td>7.91</td>\n",
       "      <td>7.69</td>\n",
       "      <td>7</td>\n",
       "      <td>No</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  College_ID   IQ  Prev_Sem_Result  CGPA  Academic_Performance  \\\n",
       "0    CLG0030  107             6.61  6.28                     8   \n",
       "1    CLG0061   97             5.52  5.37                     8   \n",
       "2    CLG0036  109             5.36  5.83                     9   \n",
       "3    CLG0055  122             5.47  5.75                     6   \n",
       "4    CLG0004   96             7.91  7.69                     7   \n",
       "\n",
       "  Internship_Experience  Extra_Curricular_Score  Communication_Skills  \\\n",
       "0                    No                       8                     8   \n",
       "1                    No                       7                     8   \n",
       "2                    No                       3                     1   \n",
       "3                   Yes                       1                     6   \n",
       "4                    No                       8                    10   \n",
       "\n",
       "   Projects_Completed Placement  \n",
       "0                   4        No  \n",
       "1                   0        No  \n",
       "2                   1        No  \n",
       "3                   1        No  \n",
       "4                   2        No  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load Dataset\n",
    "try:\n",
    "    df = pd.read_csv('CollegePlacement.csv')\n",
    "    display(df.head())\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: collegeplacement.csv not found. Please make sure the file is uploaded to the /content/ directory or specify the correct path.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "316ea538"
   },
   "source": [
    "## Prepare Data for Model Training\n",
    "\n",
    "### Subtask:\n",
    "This step involves several data preprocessing tasks: dropping the 'College_ID' column as it's irrelevant, encoding 'Internship Experience' and 'Placement' from 'Yes'/'No' to numerical '1'/'0' values, and then scaling all features using `StandardScaler`. Finally, the dataset will be split into training (80%) and testing (20%) sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9f84d640",
    "outputId": "d3e75f12-86f2-4948-baa9-eaf6b6e181a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 'College_ID' column.\n",
      "Encoded 'Internship Experience' and 'Placement' columns.\n",
      "Separated features (X) and target (y).\n",
      "Scaled features using StandardScaler.\n",
      "Split data into training (80%) and testing (20%) sets.\n",
      "\n",
      "Shape of X_train: (8000, 8)\n",
      "Shape of X_test: (2000, 8)\n",
      "Shape of y_train: (8000,)\n",
      "Shape of y_test: (2000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1. Remove the 'College_ID' column\n",
    "df = df.drop('College_ID', axis=1)\n",
    "print(\"Dropped 'College_ID' column.\")\n",
    "\n",
    "# 2. Convert 'Internship Experience' and 'Placement' to numerical values\n",
    "df['Internship_Experience'] = df['Internship_Experience'].map({'Yes': 1, 'No': 0})\n",
    "df['Placement'] = df['Placement'].map({'Yes': 1, 'No': 0})\n",
    "print(\"Encoded 'Internship Experience' and 'Placement' columns.\")\n",
    "\n",
    "# 3. Separate features (X) and target (y)\n",
    "X = df.drop('Placement', axis=1)\n",
    "y = df['Placement']\n",
    "print(\"Separated features (X) and target (y).\")\n",
    "\n",
    "# 4. Initialize StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 5. Apply StandardScaler to the features DataFrame X\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "print(\"Scaled features using StandardScaler.\")\n",
    "\n",
    "# 6. Split the scaled features X and target y into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(\"Split data into training (80%) and testing (20%) sets.\")\n",
    "\n",
    "print(\"\\nShape of X_train:\", X_train.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0ff971b2",
    "outputId": "9012521f-a994-45a6-92df-7fb12f60f6d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression model trained successfully.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Instantiate the Logistic Regression model\n",
    "model = LogisticRegression(random_state=42, max_iter=200)\n",
    "\n",
    "# Train the model using the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Logistic Regression model trained successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e6acaf06",
    "outputId": "98ee7b09-0c47-48ef-9552-1ad6e1719acc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions made on the test set.\n",
      "Logistic Regression Performance Metrics:\n",
      "Accuracy: 0.9035\n",
      "Recall: 0.6074\n",
      "F1-Score: 0.6723\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1609   65]\n",
      " [ 128  198]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# 1. Use the trained model to make predictions on the X_test dataset\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Predictions made on the test set.\")\n",
    "\n",
    "# 2. Calculate the accuracy, recall, and F1-score of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Logistic Regression Performance Metrics:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "# 3. Generate the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f\"\\nConfusion Matrix:\\n{conf_matrix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "934ec893"
   },
   "source": [
    "## Summary:\n",
    "\n",
    "### Data Analysis Key Findings\n",
    "\n",
    "*   **Data Preparation**:\n",
    "    *   The `College_ID` column was removed, and the categorical fields `Internship_Experience` and `Placement` were successfully converted from Yes/No to 1/0.\n",
    "    *   All features were scaled using `StandardScaler` to brig them onta a consistent range.\n",
    "    *   The dataset was then split into an 80 percent training set and a 20 percent testing set, giving `X_train` with 8000 samples and `X_test` with 2000 samples.\n",
    "*   **Model Training**: A Logistic Regression model was created and trained on the processed training data without any issues.\n",
    "*   **Model Evaluation**: The modelâ€™s performance on the test set produced the following results:\n",
    "    *   **Accuracy**: 0.9035, showing that the model correctly predicted 90.35 percent of cases.\n",
    "    *   **Recall**: 0.6074, indicating that it correctly captured about 60 percent of the students who were actually placed.\n",
    "    *   **F1-Score**: 0.6723, which summarizes the balance between precision and recall.\n",
    "    *   **Confusion Matrix**:\n",
    "        *   True Negatives (correctly predicted no placement): 1609\n",
    "        *   False Positives (incorrectly predicted placement): 65\n",
    "        *   False Negatives (incorrectly predicted no placement when there was one): 128\n",
    "        *   True Positives (correctly predicted placement): 198\n",
    "\n",
    "### Insights\n",
    "\n",
    "*   The model reaches strong accuracy but has lower recall, which means it tends to miss some students who were actually placed. Examining the false negatives or testing other classification methods could help improve recall.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree model trained successfully.\n",
      "Predictions made using Decision Tree on the test set.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# 1. Create and train decision tree model\n",
    "dt_model = DecisionTreeClassifier(\n",
    "    criterion='gini',        # default split metric\n",
    "    max_depth=None,          # allow full depth unless you want to tune\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "dt_model.fit(X_train, y_train)\n",
    "print(\"Decision Tree model trained successfully.\")\n",
    "\n",
    "# 2. Make predictions\n",
    "dt_y_pred = dt_model.predict(X_test)\n",
    "print(\"Predictions made using Decision Tree on the test set.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decision Tree Performance Metrics:\n",
      "Accuracy: 1.0000\n",
      "Recall: 1.0000\n",
      "F1-Score: 1.0000\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1674    0]\n",
      " [   0  326]]\n"
     ]
    }
   ],
   "source": [
    "# 3. Evaluate performance\n",
    "dt_accuracy = accuracy_score(y_test, dt_y_pred)\n",
    "dt_recall = recall_score(y_test, dt_y_pred)\n",
    "dt_f1 = f1_score(y_test, dt_y_pred)\n",
    "\n",
    "print(\"\\nDecision Tree Performance Metrics:\")\n",
    "print(f\"Accuracy: {dt_accuracy:.4f}\")\n",
    "print(f\"Recall: {dt_recall:.4f}\")\n",
    "print(f\"F1-Score: {dt_f1:.4f}\")\n",
    "\n",
    "# 4. Confusion matrix\n",
    "dt_conf_matrix = confusion_matrix(y_test, dt_y_pred)\n",
    "print(f\"\\nConfusion Matrix:\\n{dt_conf_matrix}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
